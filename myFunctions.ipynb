{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"myFunctions.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3Z360U48VpkK"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from torchvision import datasets, models, transforms, utils\n","from copy import deepcopy\n","from os import path\n","import time\n","import torch\n","import wandb\n","import plotly.graph_objs as go\n","from plotly.subplots import make_subplots\n","from sklearn.metrics import confusion_matrix\n","import plotly.figure_factory as ff"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-UphTjOPSm0e"},"source":["class myImages:\n","  def __init__(self, data_dir, n, test_dir = '', advprop = False, ):\n","    self.device = torch.device(\"cuda:0\")\n","    self.advprop = advprop\n","    if advprop:  # for models using advprop pretrained weights\n","      normalize = transforms.Lambda(lambda img: img * 2.0 - 1.0)\n","    else:\n","      self.mu = [0.485, 0.456, 0.406]\n","      self.sd = [0.229, 0.224, 0.225]\n","      normalize = transforms.Normalize(mean=self.mu, std=self.sd)\n","\n","    # https://gist.github.com/WillKoehrsen/d5de7d61e9cc2971c5aed1763f6e1ff3#file-pytorch_transforms-py\n","    data_transforms = {\n","        'train': transforms.Compose([\n","            transforms.RandomResizedCrop(n+32, scale=(0.8, 1.0)),\n","            transforms.RandomRotation(degrees=15),\n","            transforms.ColorJitter(),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.CenterCrop(size=n),\n","            transforms.ToTensor(),\n","            normalize\n","        ]),\n","        'val': transforms.Compose([\n","            transforms.Resize(n+32),\n","            transforms.CenterCrop(n),\n","            transforms.ToTensor(),\n","            normalize        \n","        ]),\n","        'test': transforms.Compose([\n","            transforms.Resize(n+32),\n","            transforms.CenterCrop(n),\n","            transforms.ToTensor(),\n","            transforms.Normalize(self.mu, self.sd)\n","        ]),        \n","    }\n","\n","    if test_dir == '':\n","      if path.isdir(path.join(data_dir, 'test')):\n","        self.arr = ['train', 'val', 'test']\n","        self.image_datasets = {x: datasets.ImageFolder(path.join(data_dir, x), data_transforms[x]) for x in self.arr}\n","      else:\n","        arr = ['train', 'val']\n","        self.image_datasets = {x: datasets.ImageFolder(path.join(data_dir, x), data_transforms[x]) for x in self.arr}\n","    else:\n","      self.arr = ['train', 'val', 'test']\n","      self.image_datasets = {x: datasets.ImageFolder(path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n","      self.image_datasets.update({x: datasets.ImageFolder(path.join(test_dir, x), data_transforms[x]) for x in ['test']})\n","\n","    self.dataloaders = {x: torch.utils.data.DataLoader(self.image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in self.arr}\n","    self.dataset_sizes = {x: len(self.image_datasets[x]) for x in self.arr}\n","    self.class_names = self.image_datasets['train'].classes\n","    self.nb_classes = len(self.class_names)\n","\n","  def imshow(self, title=None):\n","    inputs, classes = next(iter(self.dataloaders['train']))\n","    out = utils.make_grid(inputs)\n","    inp = out.numpy().transpose((1, 2, 0))\n","    if self.advprop:  # for models using advprop pretrained weights\n","      normalize = transforms.Lambda(lambda img: img * 2.0 - 1.0)\n","      # inp = inp * np.array(2.0) - np.array(1.0)\n","    else:\n","      mean = np.array(self.mu)\n","      std = np.array(self.sd)\n","      inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is None:\n","      title = [self.class_names[x] for x in classes]\n","    plt.title(title)\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","\n","  def train_model(self, model, criterion, optimizer, scheduler, num_epochs=25, name='no-name', is_inception = False):\n","    since = time.time()    \n","    val_acc_history = []\n","    test_acc_history = []    \n","\n","    if model.__class__.__name__:\n","      project_name = model.__class__.__name__ + '-' + name\n","\n","    wandb.init(project=project_name)\n","    config = wandb.config\n","    config.learning_rate = optimizer.state_dict()['param_groups'][0]['lr']\n","    config.momentum = optimizer.state_dict()['param_groups'][0]['momentum']\n","    config.step_size = scheduler.step_size\n","    config.gamma = scheduler.gamma\n","    config.max_epochs = num_epochs\n","    wandb.watch(model)\n","\n","    best_model_wts = deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","        y_true = dict()\n","        y_pred = dict()\n","\n","        y_true['val'] = y_true['test'] = np.array(-1)\n","        y_pred['val'] = y_pred['test'] = np.array(-1)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in self.arr:\n","            y_true[phase] = np.array(-1)\n","            y_pred[phase] = np.array(-1)\n","\n","            if phase == 'train':\n","                scheduler.step()\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in self.dataloaders[phase]:\n","                inputs = inputs.to(self.device)\n","                labels = labels.to(self.device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # Get model outputs and calculate loss\n","                    # Special case for inception because in training it has an auxiliary output. In train\n","                    #   mode we calculate the loss by summing the final output and the auxiliary output\n","                    #   but in testing we only consider the final output.\n","                    if is_inception and phase == \"train\":\n","                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n","                        outputs, aux_outputs = model(inputs)\n","                        loss1 = criterion(outputs, labels)\n","                        loss2 = criterion(aux_outputs, labels)\n","                        loss = loss1 + 0.4 * loss2\n","                    else:                \n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    wandb.log({phase + \"_loss\": loss})\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':                      \n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","                y_pred[phase] = np.append(y_pred[phase], preds.cpu().numpy())\n","                y_true[phase] = np.append(y_true[phase], labels.data.cpu().numpy())\n","\n","            epoch_loss = running_loss / self.dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / self.dataset_sizes[phase]\n","            \n","            z = confusion_matrix(np.delete(y_true[phase], 0), np.delete(y_pred[phase], 0))\n","            z_p = z / z.astype(np.float).sum(axis=1)[:, np.newaxis]\n","            fig = conmat(self.class_names, z)\n","            fig_p = conmat(self.class_names, z_p)\n","            wandb.log ({'epoch': epoch, 'confusion_matrix ' + phase: wandb.data_types.Plotly(fig)})\n","            wandb.log ({'epoch': epoch, 'confusion_matrix percentage ' + phase: wandb.data_types.Plotly(fig_p)})\n","            wandb.log({'epoch': epoch, 'acc' + phase: epoch_acc})\n","            wandb.log({'epoch': epoch, 'loss' + phase: epoch_loss})\n","            wandb.log({'epoch': epoch, 'acc': epoch_acc})\n","            wandb.log({'epoch': epoch, 'loss': epoch_loss})\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = deepcopy(model.state_dict())\n","                \n","            if phase == \"val\":\n","                val_acc_history.append(epoch_acc)\n","\n","            if phase == \"test\":\n","                test_acc_history.append(epoch_acc)    \n","                            \n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    self.model = model\n","    self.val_acc_history = val_acc_history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZAOpH6RsQAsG"},"source":["def visualize_model(model, dataloaders, class_names, num_images=6):\n","    was_training = model.training\n","    model.eval()\n","    images_so_far = 0\n","    fig = plt.figure()\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(dataloaders['val']):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","\n","            for j in range(inputs.size()[0]):\n","                images_so_far += 1\n","                ax = plt.subplot(num_images//2, 2, images_so_far)\n","                ax.axis('off')\n","                # ax.set_title('predicted:\\n {}'.format(class_names[preds[j]]))\n","                ax.set_title('{} ({})'.format(class_names[preds[j]], class_names[labels[j]]))\n","                imshow(inputs.cpu().data[j])\n","\n","                if images_so_far == num_images:\n","                    model.train(mode=was_training)\n","                    return\n","        model.train(mode=was_training)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7hed2v_XsNrr"},"source":["def conmat(class_names, z):\n","  # https://stackoverflow.com/questions/60860121/plotly-how-to-make-an-annotated-confusion-matrix-using-a-heatmap\n","  z = [[round(y, 4) for y in x] for x in z]    \n","  z_text = [[str(y) for y in x] for x in z]\n","  fig = ff.create_annotated_heatmap(z, x=class_names, y=class_names, annotation_text=z_text, colorscale='Viridis')\n","  fig.update_layout(title_text='<i><b>Confusion matrix</b></i>',\n","                    yaxis = dict(title='true'),\n","                    xaxis = dict(title='pred')\n","  )\n","  fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n","    x=0.5,\n","    y=-0.15,\n","    showarrow=False,\n","    text=\"Predicted value\",\n","    xref=\"paper\",\n","    yref=\"paper\"))\n","  \n","  fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n","    x=-0.35,\n","    y=0.5,\n","    showarrow=False,\n","    text=\"Real value\",\n","    textangle=-90,\n","    xref=\"paper\",\n","    yref=\"paper\"))\n","  \n","  fig.update_layout(margin=dict(t=50, l=200))\n","  fig['data'][0]['showscale'] = True\n","  return (fig)\n"],"execution_count":null,"outputs":[]}]}